{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lm8Diq-7TxhE",
    "outputId": "003cd5af-9612-4e24-c52b-9201258a515b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dPYqovD7MRXy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools\n",
    "import os\n",
    "from time import perf_counter\n",
    "from scipy.sparse.linalg import svds\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMYNEfVyULok"
   },
   "source": [
    "# Code for NMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yC_Fm1MjTYtm"
   },
   "outputs": [],
   "source": [
    "def print_final_msg(times: list[float], errors: list[float], init_time: float, i: int):\n",
    "    avg_time_per_iter = np.mean(times)\n",
    "    total_time = init_time + np.sum(times)\n",
    "    print(f\"Final relative error: {100 * errors[-1]}%, after {i + 1} iterations.\")\n",
    "    print(f\"Initialization time: {init_time:3f} secs\")\n",
    "    print(f\"Mean time per iteration: {avg_time_per_iter:3f} secs\")\n",
    "    print(f\"Total time: {total_time:3f} secs\")\n",
    "\n",
    "\n",
    "def compute_abs_error(Theta: np.ndarray, X: np.ndarray) -> float:\n",
    "    return np.linalg.norm(np.maximum(0, Theta) - X, ord=\"fro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-NMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GuJ5bZ54TMXz"
   },
   "outputs": [],
   "source": [
    "\n",
    "def a_nmd(\n",
    "    X: npt.NDArray[np.float_],\n",
    "    r: int,\n",
    "    Theta0: npt.NDArray[np.float_],\n",
    "    beta: float = 0.9,\n",
    "    eta: float = 0.4,\n",
    "    gamma: float = 1.1,\n",
    "    gamma_bar: float = 1.05,\n",
    "    max_iters: int = 1000,\n",
    "    tol: float = 1.0e-4,\n",
    "    tol_over_10iters: float = 1.0e-5,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    \"\"\"Aggressive Momentum NMD (A-NMD)\n",
    "\n",
    "    Args:\n",
    "        X (npt.NDArray[np.float_]): (m, n) sparse non-negative matrix\n",
    "        r (int): approximation rank\n",
    "        Theta0 (npt.NDArray[np.float_]): initial Theta. Defaults to np.random.randn(m, n) if none is provided.\n",
    "        beta (float, optional): initial momentum parameter. Defaults to 0.9.\n",
    "        eta (float, optional): hyperparameter. Defaults to 0.4.\n",
    "        gamma (float, optional): hyperparameter. Defaults to 1.05.\n",
    "        gamma_bar (float, optional): hyperparameter. Defaults to 1.1.\n",
    "        max_iters (int, optional): maximum number of iterations. Defaults to 1000.\n",
    "        tol (float, optional):  stopping criterion on the relative error: ||X-max(0,WH)||/||X|| < tol. Defaults to 1e-4.\n",
    "        tol_over_10iters (float, optional): stopping criterion tolerance on 10 successive errors: abs(errors[i] - errors[i-10]) < tol_err. Defaults to 1e-5.\n",
    "        verbose (bool, optional): print information to console. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        (npt.NDArray[np.float_], list[float], int, list[float]): Theta, errors_relative, number of iterations, times\n",
    "    \"\"\"\n",
    "    if np.any(X < 0):\n",
    "        raise ValueError(\"X must be non-negative.\")\n",
    "\n",
    "    ## Code different than paper\n",
    "    # assert eta > 1.0\n",
    "    # assert eta > gamma\n",
    "    # assert gamma > gamma_bar\n",
    "\n",
    "    start_time_init = perf_counter()\n",
    "    Theta0 = np.random.randn(m, n) if Theta0 is None else Theta0\n",
    "    beta_bar = 1.0\n",
    "    beta_history = [beta]\n",
    "\n",
    "    m, n = X.shape\n",
    "    x_is_zero = X == 0\n",
    "    x_is_pos = np.invert(x_is_zero)\n",
    "\n",
    "    Z0 = np.zeros((m, n))\n",
    "    Z0[x_is_pos] = X[x_is_pos]  # Z0 = X.copy()\n",
    "\n",
    "    Z = Z0\n",
    "    Theta = Theta0\n",
    "    Z_old = Z0.copy()  # Z_old = X.copy()\n",
    "    Theta_old = Theta0.copy()\n",
    "\n",
    "    norm_X = np.linalg.norm(X, ord=\"fro\")\n",
    "    errors_relative = [compute_abs_error(Theta, X) / norm_X]\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Running A-NMD, evolution of [iteration number : relative error in %] - time per iteration\"\n",
    "        )\n",
    "\n",
    "    initialization_time = perf_counter() - start_time_init\n",
    "    times = [0.0]\n",
    "    for i in range(max_iters):\n",
    "        start_time_iteration = perf_counter()\n",
    "\n",
    "        Z = np.minimum(0.0, Theta * x_is_zero)  # construct_utility\n",
    "        Z += X * x_is_pos  # construct_utility\n",
    "        Z += beta * (Z - Z_old)  # momentum on Z\n",
    "\n",
    "        U, d, Vt = svds(Z, r)  # find_low_rank\n",
    "        D = np.diag(d)  # find_low_rank\n",
    "        Theta = U @ D @ Vt  # find_low_rank\n",
    "\n",
    "        errors_relative.append(compute_abs_error(Theta, X) / norm_X)\n",
    "\n",
    "        if errors_relative[-1] < tol:\n",
    "            if verbose:\n",
    "                print(f\"Converged: ||X-max(0,WH)||/||X|| < {tol}\")\n",
    "            times.append(perf_counter() - start_time_iteration)\n",
    "            break\n",
    "\n",
    "        if (\n",
    "            i >= 10\n",
    "            and abs(errors_relative[-1] - errors_relative[-11]) < tol_over_10iters\n",
    "        ):\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Converged: abs(rel. err.(i) - rel. err.(i-10)) < {tol_over_10iters}\"\n",
    "                )\n",
    "            times.append(perf_counter() - start_time_iteration)\n",
    "            break\n",
    "\n",
    "        if i < max_iters - 1:\n",
    "            Theta += beta * (Theta - Theta_old)\n",
    "\n",
    "        if i > 1:\n",
    "            if compute_abs_error(Theta, X) < compute_abs_error(Theta_old, X):\n",
    "                # if loss decreases:\n",
    "                # compute new momentum parameter\n",
    "                beta = min(beta_bar, gamma * beta)\n",
    "                beta_bar = min(1, gamma_bar * beta)  # in paper: gamma_bar * beta_bar\n",
    "                beta_history.append(beta)\n",
    "\n",
    "                Z_old = Z.copy()\n",
    "                Theta_old = Theta.copy()\n",
    "            else:\n",
    "                # if loss increases or stays the same:\n",
    "                #\n",
    "                beta *= eta\n",
    "                beta_history.append(beta)\n",
    "                beta_bar = beta_history[\n",
    "                    i - 2\n",
    "                ]  # reset beta bar to last beta that caused a decrease in loss\n",
    "\n",
    "                Z = Z_old.copy()\n",
    "                Theta = Theta_old.copy()\n",
    "\n",
    "        times.append(perf_counter() - start_time_iteration)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[{i} : {(100 * errors_relative[-1]):5f}] - {times[-1]:3f} secs\")\n",
    "\n",
    "    if verbose:\n",
    "        print_final_msg(times, errors_relative, initialization_time, i)\n",
    "\n",
    "    return Theta, errors_relative, i + 1, times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B-NMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2NEQcgj8TmoQ"
   },
   "outputs": [],
   "source": [
    "def nmd_3b(\n",
    "    X: npt.NDArray[np.float_],\n",
    "    r: int,\n",
    "    W0: npt.NDArray[np.float_] = None,\n",
    "    H0: npt.NDArray[np.float_] = None,\n",
    "    beta1: float = 0.7,\n",
    "    max_iters: int = 1000,\n",
    "    tol: float = 1e-4,\n",
    "    tol_over_10iters: float = 1e-5,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    \"\"\"NMD using three-block alternating minimization.\n",
    "\n",
    "    Args:\n",
    "        X (npt.NDArray[np.float_]): (m, n) sparse non-negative matrix\n",
    "        r (int): approximation rank\n",
    "        W0 (npt.NDArray[np.float_], optional): initial W. Defaults to np.random.randn(m, r) if none is provided.\n",
    "        H0 (npt.NDArray[np.float_], optional): initial H. Defaults to np.random.randn(r, n) if none is provided.\n",
    "        beta1 (float, optional): momentum parameter. Defaults to 0.7.\n",
    "        max_iters (int, optional): maximum number of iterations. Defaults to 1000.\n",
    "        tol (float, optional):  stopping criterion on the relative error: ||X-max(0,WH)||/||X|| < tol. Defaults to 1e-4.\n",
    "        tol_over_10iters (float, optional): stopping criterion tolerance on 10 successive errors: abs(errors[i] - errors[i-10]) < tol_err. Defaults to 1e-5.\n",
    "        verbose (bool, optional): print information to console. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        (npt.NDArray[np.float_], list[float], int, list[float]): Theta, errors_relative, number of iterations, times\n",
    "    \"\"\"\n",
    "\n",
    "    if np.any(X < 0):\n",
    "        raise ValueError(\"X must be non-negative.\")\n",
    "\n",
    "    start_time_init = perf_counter()\n",
    "\n",
    "    m, n = X.shape\n",
    "    W0 = np.random.randn(m, r) if W0 is None else W0\n",
    "    H0 = np.random.randn(r, n) if H0 is None else H0\n",
    "\n",
    "    norm_X = np.linalg.norm(X, \"fro\")\n",
    "    x_is_zero = X == 0\n",
    "    x_is_pos = np.invert(x_is_zero)\n",
    "\n",
    "    Z = np.zeros((m, n))\n",
    "    Z[x_is_pos] = X[x_is_pos]\n",
    "\n",
    "    W, H = W0, H0\n",
    "    Theta = W @ H\n",
    "    Z_old, Theta_old = Z.copy(), Theta.copy()\n",
    "\n",
    "    errors = [compute_abs_error(Theta, X) / norm_X]\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Running 3B-NMD, evolution of [iteration number : relative error in %] - time per iteration\"\n",
    "        )\n",
    "\n",
    "    initialization_time = perf_counter() - start_time_init\n",
    "    times = [0.0]\n",
    "    for i in range(0, max_iters):\n",
    "        start_time_iteration = perf_counter()\n",
    "\n",
    "        Z = np.minimum(0.0, Theta * x_is_zero)\n",
    "        Z += X * x_is_pos\n",
    "        Z *= 1 + beta1\n",
    "        Z -= beta1 * Z_old\n",
    "\n",
    "        # rcond to silence future warning\n",
    "        W = np.linalg.lstsq(H @ H.T, H @ Z.T, rcond=None)[0].T\n",
    "        H = np.linalg.lstsq(W.T @ W, W.T @ Z, rcond=None)[0]\n",
    "        Theta = W @ H\n",
    "\n",
    "        errors.append(compute_abs_error(Theta, X) / norm_X)\n",
    "        if errors[-1] < tol:\n",
    "            if verbose:\n",
    "                print(f\"Converged: ||X-max(0,WH)||/||X|| < {tol}\")\n",
    "            times.append(perf_counter() - start_time_iteration)\n",
    "            break\n",
    "\n",
    "        if i >= 10 and abs(errors[-1] - errors[-11]) < tol_over_10iters:\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Converged: abs(rel. err.(i) - rel. err.(i-10)) < {tol_over_10iters}\"\n",
    "                )\n",
    "            times.append(perf_counter() - start_time_iteration)\n",
    "            break\n",
    "\n",
    "        if i < max_iters - 1:\n",
    "            Theta *= 1.0 + beta1\n",
    "            Theta -= beta1 * Theta_old\n",
    "\n",
    "        Z_old, Theta_old = Z.copy(), Theta.copy()\n",
    "\n",
    "        times.append(perf_counter() - start_time_iteration)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[{i} : {(100 * errors[-1]):5f}] - {times[-1]:3f} secs\")\n",
    "\n",
    "    if verbose:\n",
    "        print_final_msg(times, errors, initialization_time, i)\n",
    "\n",
    "    return Theta, errors, i + 1, times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuclear_norm_init(\n",
    "    X: np.ndarray, m: int, n: int, r: int, seed: int, verbose: bool = False\n",
    ") -> (np.ndarray, np.ndarray):\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    # Theta1 = np.random.randn(m, n, rng=rng)\n",
    "    Theta1 = rng.standard_normal(size=(m, n))\n",
    "    Theta2, _ = nmd_nuclear_bt(X, Theta1, 3, verbose=verbose)\n",
    "    ua, sa, va = np.linalg.svd(Theta2, full_matrices=False)\n",
    "    sa = np.diag(sa)[:r, :r]\n",
    "    W0 = ua[:, :r]\n",
    "    H0 = sa @ va[:r, :]\n",
    "    return W0, H0\n",
    "\n",
    "\n",
    "def nmd_nuclear_bt(\n",
    "    X: npt.ArrayLike, Theta: npt.ArrayLike, max_iter: int, verbose: bool = False\n",
    ") -> (np.ndarray, list[float]):\n",
    "    ## LOOKS GOOD TO BE TESTED\n",
    "    assert np.all(X >= 0)\n",
    "\n",
    "    x_is_zero = X == 0\n",
    "    x_is_pos = np.invert(x_is_zero)\n",
    "\n",
    "    alpha = 1 / 1**0.1  # Initial choice for alpha\n",
    "    Theta[x_is_pos] = X[x_is_pos]  # Set the fixed components of Theta\n",
    "    Theta[x_is_zero] = np.minimum(0, Theta[x_is_zero])\n",
    "\n",
    "    nuclear_norms = []\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        if verbose:\n",
    "            print(f\"Iteration { i + 1 } out of { max_iter }\")\n",
    "        U, D, Vt = np.linalg.svd(Theta, full_matrices=False)\n",
    "        nuclear_norms.append(np.sum(np.diag(D)))  # Nuclear norm eval\n",
    "\n",
    "        # backtracking\n",
    "        if i > 0 and nuclear_norms[i] < nuclear_norms[i - 1]:\n",
    "            alpha *= 1.2\n",
    "        else:\n",
    "            alpha *= 0.7\n",
    "\n",
    "        # Update Theta\n",
    "        # Theta = Theta - alpha * (U @ Vt)\n",
    "        Theta -= alpha * (U @ Vt)\n",
    "\n",
    "        # Project Theta\n",
    "        Theta[x_is_pos] = X[x_is_pos]\n",
    "        Theta[x_is_zero] = np.minimum(0, Theta[x_is_zero])\n",
    "\n",
    "    return Theta, nuclear_norms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-ORyS6yUbpl"
   },
   "source": [
    "# Code for simulating sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eA8znkTqUfej"
   },
   "outputs": [],
   "source": [
    "def generate_nonnegative_matrix(m: int, n: int, r: int, c: float = 0.0) -> npt.NDArray:\n",
    "    \"\"\"Generates a (m, n) matrix X with rank r\n",
    "\n",
    "    X is generated as min(0, W1@H1), where W1 is of size (m, r)\n",
    "    and H1 of size (r, n), entries in W1 and H1 are standard normal, therefore,\n",
    "    on average, 50% of the entries of X are zero if c == 0\n",
    "\n",
    "    Args:\n",
    "        m (int): Number of rows in X\n",
    "        n (int): Number of columns in X\n",
    "        r (int): Desired rank\n",
    "        c (float): sparsity parameter 0 <= c <= 1.7\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A matrix of shape (m, n) with non-negative entries.\n",
    "    \"\"\"\n",
    "    W = np.random.randn(m, r) - c\n",
    "    H = np.random.randn(r, n) + c\n",
    "    return W @ H\n",
    "\n",
    "\n",
    "def get_sparsity(X: npt.NDArray) -> float:\n",
    "    \"\"\"Computes the sparsity of a matrix X\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): A matrix\n",
    "\n",
    "    Returns:\n",
    "        float: The sparsity of X\n",
    "    \"\"\"\n",
    "    return 1.0 - np.count_nonzero(X) / X.size\n",
    "\n",
    "\n",
    "def try_c_values(m, n, r, reps):\n",
    "    c = np.arange(0, 1.7, 0.01)\n",
    "    sparsity = np.zeros((reps, c.size))\n",
    "    for i in range(c.size):\n",
    "        for j in range(reps):\n",
    "            X = generate_nonnegative_matrix(m, n, r, c[i])\n",
    "            sparsity[j, i] = get_sparsity(np.maximum(0, X))\n",
    "    df = pd.DataFrame(sparsity, columns=c)\n",
    "    return df\n",
    "\n",
    "\n",
    "def estimate_sparsity_param(sparsity: float, m: int, n: int, r: int, reps: int = 50) -> float:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        sparsity (float): desired sparsity\n",
    "        m (int): number of rows of the matrix\n",
    "        n (int): numer of columns\n",
    "        r (int): rank of the matrix\n",
    "        reps (int, optional): repetitions. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        float: c value that gives the desired sparsity\n",
    "    \"\"\"\n",
    "    df = try_c_values(m, n, r, reps)\n",
    "    return float(df.columns[np.argmin(abs(df.mean(axis=0) - sparsity))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UuhV0cbtUlAz"
   },
   "outputs": [],
   "source": [
    "# Function to save results and matrices using pickle\n",
    "def save_results_and_matrices(results, file_path):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "def make_parameter_combinations(**kwargs):\n",
    "    \"\"\"\n",
    "    Generate the cartesian product of multiple iterables passed as named arguments.\n",
    "\n",
    "    This function takes any number of named arguments, where each argument is expected\n",
    "    to be an iterable. It returns a list of dictionaries, each representing a unique\n",
    "    combination of elements from the iterables. The keys in the dictionaries are the\n",
    "    names of the arguments, and the values are the corresponding elements from the iterables.\n",
    "\n",
    "    Parameters:\n",
    "    **kwargs: Arbitrary number of named arguments, each being an iterable.\n",
    "\n",
    "    Returns:\n",
    "    List[Dict]: A list of dictionaries, each containing a unique combination of elements\n",
    "                from the provided iterables. The keys in the dictionaries correspond to\n",
    "                the names of the arguments.\n",
    "\n",
    "    Example:\n",
    "    >>> get_parameter_combinations(rank=[8, 16, 32], algo=[\"a\", \"b\"])\n",
    "    [{'rank': 8, 'algo': 'a'}, {'rank': 8, 'algo': 'b'}, ..., {'rank': 32, 'algo': 'b'}]\n",
    "    \"\"\"\n",
    "    keys = kwargs.keys()\n",
    "    values_product = itertools.product(*kwargs.values())\n",
    "    return [dict(zip(keys, values)) for values in values_product]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61TOCGuoUoAk"
   },
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDmgdcTpUs9c"
   },
   "source": [
    "## Fixed Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXPZGHttU1Tp"
   },
   "source": [
    "Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Kch1hXTUU2Tk"
   },
   "outputs": [],
   "source": [
    "#max_iterations = 30000\n",
    "max_iterations = 10000\n",
    "tol = 1e-2\n",
    "tol_error = 1e-3\n",
    "beta = 0.7\n",
    "eta = 0.4\n",
    "gamma = 1.1\n",
    "gamma_bar = 1.05\n",
    "beta1 = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qMvVS_SU7FY"
   },
   "source": [
    "Simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xiSos9gjU71S"
   },
   "outputs": [],
   "source": [
    "reps = 5 # 10 reichen\n",
    "inits = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cKWPtJ3fVaJp"
   },
   "outputs": [],
   "source": [
    "# storage_dir = \"/content/drive/MyDrive/NMD_Grid_Simulation/\"\n",
    "storage_dir = \"./results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8a45qNFVEl9"
   },
   "source": [
    "## Parameters Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTLYdeBkVHJ0",
    "outputId": "b7a93014-4736-47a7-f4f9-1419f6d0dfe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dimension': 5000, 'rank': 8, 'sparsity': 0.5}, {'dimension': 5000, 'rank': 8, 'sparsity': 0.75}, {'dimension': 5000, 'rank': 8, 'sparsity': 0.9}, {'dimension': 5000, 'rank': 8, 'sparsity': 0.95}, {'dimension': 5000, 'rank': 8, 'sparsity': 0.99}, {'dimension': 5000, 'rank': 16, 'sparsity': 0.5}, {'dimension': 5000, 'rank': 16, 'sparsity': 0.75}, {'dimension': 5000, 'rank': 16, 'sparsity': 0.9}, {'dimension': 5000, 'rank': 16, 'sparsity': 0.95}, {'dimension': 5000, 'rank': 16, 'sparsity': 0.99}, {'dimension': 5000, 'rank': 32, 'sparsity': 0.5}, {'dimension': 5000, 'rank': 32, 'sparsity': 0.75}, {'dimension': 5000, 'rank': 32, 'sparsity': 0.9}, {'dimension': 5000, 'rank': 32, 'sparsity': 0.95}, {'dimension': 5000, 'rank': 32, 'sparsity': 0.99}, {'dimension': 5000, 'rank': 64, 'sparsity': 0.5}, {'dimension': 5000, 'rank': 64, 'sparsity': 0.75}, {'dimension': 5000, 'rank': 64, 'sparsity': 0.9}, {'dimension': 5000, 'rank': 64, 'sparsity': 0.95}, {'dimension': 5000, 'rank': 64, 'sparsity': 0.99}]\n"
     ]
    }
   ],
   "source": [
    "dimension = [5000]\n",
    "rank = [8, 16, 32, 64]\n",
    "#rank = [64]\n",
    "sparsity = [.5, .75, .9, .95, .99]\n",
    "#sparsity = [.99]\n",
    "\n",
    "parameter_combinations = make_parameter_combinations(dimension=dimension, rank=rank, sparsity=sparsity)\n",
    "print(parameter_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vefk6nnLVLyO",
    "outputId": "b838133b-b49c-4213-a102-ba6f51e90707"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parameter_combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xyA5yPZVQXb"
   },
   "source": [
    "## Experiment Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bnqauUVtVSV-",
    "outputId": "be30fe67-2061-4c37-bd11-bc4abe433037",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Parameter combination 1 out of 20\n",
      "Dim: 5000 // Rank: 8 // Sparsity: 0.5\n",
      "File exists... skipping\n",
      "--> Parameter combination 2 out of 20\n",
      "Dim: 5000 // Rank: 8 // Sparsity: 0.75\n",
      "File exists... skipping\n",
      "--> Parameter combination 3 out of 20\n",
      "Dim: 5000 // Rank: 8 // Sparsity: 0.9\n",
      "File exists... skipping\n",
      "--> Parameter combination 4 out of 20\n",
      "Dim: 5000 // Rank: 8 // Sparsity: 0.95\n",
      "File exists... skipping\n",
      "--> Parameter combination 5 out of 20\n",
      "Dim: 5000 // Rank: 8 // Sparsity: 0.99\n",
      "File exists... skipping\n",
      "--> Parameter combination 6 out of 20\n",
      "Dim: 5000 // Rank: 16 // Sparsity: 0.5\n",
      "File exists... skipping\n",
      "--> Parameter combination 7 out of 20\n",
      "Dim: 5000 // Rank: 16 // Sparsity: 0.75\n",
      "File exists... skipping\n",
      "--> Parameter combination 8 out of 20\n",
      "Dim: 5000 // Rank: 16 // Sparsity: 0.9\n",
      "--> Estimated sparsity param for 0.9: 0.65\n",
      "# Replication 1 out of 5\n",
      "--> Actual Sparsity: 0.90358396\n",
      "# Initialization 1 out of 2\n",
      "# Initialization 2 out of 2\n",
      "# Replication 2 out of 5\n",
      "# Initialization 1 out of 2\n",
      "# Initialization 2 out of 2\n",
      "# Replication 3 out of 5\n",
      "# Initialization 1 out of 2\n",
      "# Initialization 2 out of 2\n",
      "# Replication 4 out of 5\n",
      "# Initialization 1 out of 2\n",
      "# Initialization 2 out of 2\n"
     ]
    }
   ],
   "source": [
    "# Initialize results and matrices data structures\n",
    "all_results = []\n",
    "\n",
    "for i, params in enumerate(parameter_combinations):\n",
    "    print(f\"--> Parameter combination {i+1} out of {len(parameter_combinations)}\")\n",
    "\n",
    "    m = params['dimension']\n",
    "    r = params['rank']\n",
    "    sparsity_lvl = params['sparsity']\n",
    "    print(f\"Dim: {m} // Rank: {r} // Sparsity: {sparsity_lvl}\")\n",
    "    n = m\n",
    "\n",
    "    path4pickle = f\"{storage_dir}results_dim{m}_rank{r}_sparsity{sparsity_lvl}.pkl\"\n",
    "\n",
    "    # check if pickle already exists if yes\n",
    "    if os.path.isfile(path4pickle):\n",
    "      print(\"File exists... skipping\")\n",
    "      continue\n",
    "\n",
    "    if sparsity_lvl == .5:\n",
    "        c = 0.0\n",
    "    else:\n",
    "        c = estimate_sparsity_param(sparsity=sparsity_lvl,m=m, n=n, r=r, reps=15)\n",
    "    print(f\"--> Estimated sparsity param for {sparsity_lvl}: {c}\")\n",
    "    for j in range(reps):\n",
    "\n",
    "        print(f\"# Replication {j+1} out of {reps}\")\n",
    "        # Generate matrices\n",
    "        matrix_generation_seed_W1 = int(datetime.now().timestamp())\n",
    "        rng_W1 = np.random.default_rng(seed=matrix_generation_seed_W1)\n",
    "        #W1 = np.random.randn(m, r, rng=rng_W1) + c\n",
    "        W1 = rng_W1.standard_normal(size=(m, r)) + c\n",
    "\n",
    "        matrix_generation_seed_H1 = int(datetime.now().timestamp())\n",
    "        rng_H1 = np.random.default_rng(seed=matrix_generation_seed_H1)\n",
    "        #H1 = np.random.randn(r, n, rng=rng_H1) - c\n",
    "        H1 = rng_W1.standard_normal(size=(r, n)) - c\n",
    "        X = np.maximum(0, W1 @ H1)\n",
    "\n",
    "        actual_sparsity = np.sum(X == 0) / X.size\n",
    "        \n",
    "        if j == 0:\n",
    "            print(f\"--> Actual Sparsity: {actual_sparsity}\")\n",
    "\n",
    "        for k in range(inits):\n",
    "\n",
    "            print(f\"# Initialization {k+1} out of {inits}\")\n",
    "\n",
    "            # Nuclear Initialization\n",
    "            initialization_seed = int(datetime.now().timestamp())\n",
    "            W0, H0 = nuclear_norm_init(X, m=m, n=n, r=r, seed=initialization_seed)\n",
    "            Theta0 = W0 @ H0\n",
    "\n",
    "            # A-NMD\n",
    "            T_ANMD, rel_err_ANMD, it_ANMD, t_ANMD = a_nmd(X, r,\n",
    "                                                         Theta0=Theta0,\n",
    "                                                         max_iters=max_iterations,\n",
    "                                                         tol=tol,\n",
    "                                                         tol_over_10iters=tol_error,\n",
    "                                                         beta=beta,\n",
    "                                                         eta=eta,\n",
    "                                                         gamma=gamma,\n",
    "                                                         gamma_bar=gamma_bar,\n",
    "                                                         verbose=False)\n",
    "\n",
    "            # 3B-NMD\n",
    "            T_3B, rel_err_3B, it_3B, t_3B = nmd_3b(X, r,\n",
    "                                                   W0=W0, H0=H0,\n",
    "                                                   max_iters=max_iterations,\n",
    "                                                   tol=tol,\n",
    "                                                   tol_over_10iters=tol_error,\n",
    "                                                   beta1=beta1,\n",
    "                                                   verbose=False)\n",
    "\n",
    "            # Store results and matrices\n",
    "            all_results.append({\n",
    "                \"norm_X\": np.linalg.norm(X, ord='fro'),\n",
    "                \"initialization_seed\": initialization_seed,\n",
    "                \"matrix_generation_seed_W1\": matrix_generation_seed_W1,\n",
    "                \"matrix_generation_seed_H1\": matrix_generation_seed_H1,\n",
    "                \"m\": m, \"n\": n, \"r\": r, \"sparsity_level\": sparsity_lvl, \"c\": c,\n",
    "                \"actual_sparsity\": actual_sparsity,\n",
    "                \"replication\": j, \"initialization\": k,\n",
    "                \"A_NMD\": {\n",
    "                    \"times\": t_ANMD,\n",
    "                    \"iters\": it_ANMD,\n",
    "                    \"rel_errors\": rel_err_ANMD,\n",
    "                },\n",
    "                \"3B_NMD\": {\n",
    "                    \"times\": t_3B,\n",
    "                    \"iters\": it_3B,\n",
    "                    \"rel_errors\": rel_err_3B,\n",
    "                }\n",
    "            })\n",
    "\n",
    "        # after one param combination - so after a few inits\n",
    "        if j == reps - 1:\n",
    "            # Save results and matrices to disk using pickle\n",
    "            save_results_and_matrices(all_results,  path4pickle)\n",
    "            all_results = []"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "CMYNEfVyULok",
    "f-ORyS6yUbpl"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
